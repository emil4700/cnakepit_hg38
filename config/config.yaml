##################################################################################
# Only this file is to be changed when running the pipeline
# (and the Snakefile rule all and maybe pipeline_job.sh for cluster submission)
##################################################################################


#--- Requires individual changes --------------------------------------------------

# This pipeline is mainly built for hybridization-capture based NGS data, but is also implements changes required for amplicon sequencing data. Those changes include:
#     - ignoring of off-target reads (theoretically, no off-target reads are sequenced.
#     - no flagging of PCR duplicates (all of the amplified reads are in fact PCR duplicates by design) 
amplicon: false

# Do the samples require specific preprocessing for unique molecular identifiers (UMIs)? (Specifically for HRD dataset)
contain_UMIs: true

# Experimental filtering of reference genome
filter_reference: false

# compute mappability for the reference genome or download the premade one from CNVkit?
compute_mappability: true

# Path to reference genome and its index file. Will be downloaded if absent. Current pipeline settings are for hg38.
reference:
  fasta: "/fast/work/projects/cubit/18.12/static_data/reference/hg38/ucsc/hg38.fa"
  index: "/fast/work/projects/cubit/18.12/static_data/reference/hg38/ucsc/hg38.fa.fai"
# fasta: "resources/reference/hg38.fa" # use this if you wish to download the reference file
# ref_index: "resources/reference/hg38.fa.fai"
  dict: "resources/reference/hg38.dict"
  fasta_link: "storage.googleapis.com/genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta"
  index_link: "storage.googleapis.com/genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta.fai"
  dict_link: "storage.googleapis.com/genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.dict"

data:
  samples_in_directory: false # boolean, are samples or their symlinks in resource/data?
  # if previous is false, give path to sample sheet
  sample_sheet_path: "resources/data/sample_sheet.tsv" # tab-separated columns: sample|fq1|fq2

# chromosome column must be like "chr1", not "1"
# MH panel design
panel_design: "resources/paneldesign/MH_Covered_liftover_hg38.bed"
# SIGN-OC panel design
# panel_design: "resources/paneldesign/S3287512_Covered.bed"

adapter_sequences: "resources/adapter/panel-adapter.fa" # for trimming


#--- Does usually not require changes ---------------------------------------------
# The paths to reference files which will be downloaded if absent

gnomad_af_only:
  vcf: "resources/germline-resource/af-only-gnomad.hg38.vcf.gz"
  index: "resources/germline-resource/af-only-gnomad.hg38.vcf.gz.tbi"
  vcf_link: "www.bcgsc.ca/downloads/morinlab/reference/af-only-gnomad.hg38.vcf.gz"
  index_link: "www.bcgsc.ca/downloads/morinlab/reference/af-only-gnomad.hg38.vcf.gz.tbi"

common_germline_variants:
  vcf: "resources/common-biallelic/small_exac_common_3.hg38.vcf.gz"
  index: "resources/common-biallelic/small_exac_common_3.hg38.vcf.gz.tbi"
  vcf_link: "http://storage.googleapis.com/gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz"
  index_link: "http://storage.googleapis.com/gatk-best-practices/somatic-hg38/small_exac_common_3.hg38.vcf.gz.tbi"

mappability:
  bed: "resources/mappability/access-5k-mappable.hg19.bed"
  link: "github.com/etal/cnvkit/raw/master/data/access-5k-mappable.hg19.bed"

sv_blacklist:
  bed: "resources/mappability/sv_blacklist.bed"
  link: "http://cf.10xgenomics.com/supp/genome/GRCh38/sv_blacklist.bed"



#--- variance calling parameters: bcf tools --------------------------------------

# bcftools call:
# caller: valid options include -c/--consensus-caller or -m/--multiallelic-caller
caller: "-m"
# other options e.g. "--ploidy 1 --prior 0.001"
caller_options: "--ploidy 1 --prior 0.001"

# bcftools mpileup:
# e.g. "--max-depth 100 --min-BQ 15"
mpileup_options: "--max-depth 100 --min-BQ 15"



#TESTING PURPOSES:
ref_fil: "results/filter_ref/hg38_filtered.fa"